{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1da970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdzai\\miniconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7493f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"HF_TOKEN\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a1932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556bc1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 210016, 672, 563, 4329], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"diaz this is!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e949c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  6974,   496, 23181,  1948,   531,  1138,  1156,  4945]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = tokenizer(\"Write a python program to add two numbers\", return_tensors=\"pt\")\n",
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392576c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\", dtype=torch.bfloat16, cache_dir=\"./model_cache\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ae7475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-14.1875,  -1.1250,   4.6562,  ..., -14.6250, -14.6875, -14.6250],\n",
       "         [-17.5000,  -0.6094,  -3.5000,  ..., -17.8750, -17.8750, -17.7500],\n",
       "         [-12.1875,  -2.9688,  -4.9688,  ..., -13.4375, -13.4375, -13.3125],\n",
       "         ...,\n",
       "         [-16.5000,  -3.2969,  -1.6016,  ..., -18.3750, -18.3750, -18.2500],\n",
       "         [-17.5000,  -2.4844,   2.6250,  ..., -19.7500, -19.7500, -19.6250],\n",
       "         [-17.6250,  -1.9375,  -0.3652,  ..., -20.1250, -20.2500, -20.0000]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(input_ids = input_tokens[\"input_ids\"])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953c19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,   6974,    496,  23181,   1948,    531,   1138,   1156,   4945,\n",
       "         236761,    108,   2717,   6719,    107, 236865,  10474, 236743, 236770,\n",
       "         236787,  10352,   6079,  40442,   6675,    107,   3744, 236770,    578,\n",
       "         236743, 236770, 236771,    107,   3744, 236778,    578, 236743, 236810,\n",
       "            107,   2330, 236779,   3709,    578,   1152, 236770,    900,   1152,\n",
       "         236778,    107,   1995,    885,    818,   2324,    529,    827,   1152,\n",
       "         236770, 236764,    623,    624,    827,   1152, 236778, 236764,    623,\n",
       "            511,  23168,   2324, 236779,   3709, 236768,    108, 236865,  10474,\n",
       "         236743, 236778, 236787,  10352,    496,   7350,    107,   3744, 236770,\n",
       "            578, 236743, 236770, 236771,    107,   3744, 236778,    578, 236743,\n",
       "         236810,    107,   1708,    858,    528,   2644, 236769, 236770, 236764,\n",
       "           1152, 236778,   1473,    107,    140,   3744, 236770,    578,   1152,\n",
       "         236770]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_out = model.generate(input_ids = input_tokens[\"input_ids\"], max_new_tokens=100)\n",
    "gen_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d6162c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Write a python program to add two numbers.\\n\\n```python\\n# Method 1: Using basic arithmetic operations\\nnum1 = 10\\nnum2 = 5\\nsum_result = num1 + num2\\nprint(\"The sum of\", num1, \"and\", num2, \"is:\", sum_result)\\n\\n# Method 2: Using a loop\\nnum1 = 10\\nnum2 = 5\\nfor i in range(1, num2):\\n    num1 = num1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e34715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
